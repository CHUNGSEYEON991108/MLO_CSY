# mlops_csy/model_utils.py
import os
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler

def train_model(df, target_col='ì±„ë¬´ ë¶ˆì´í–‰ ì—¬ë¶€'):
    # íŠ¹ì§•(X)ê³¼ ëª©í‘œ ë³€ìˆ˜(y) ì •ì˜
    X = df.drop(columns=[target_col, 'UID'])  # 'ì±„ë¬´ ë¶ˆì´í–‰ ì—¬ë¶€'ì™€ 'UID'ë¥¼ ì œì™¸í•œ ë°ì´í„° ì‚¬ìš©
    y = df[target_col]  # 'ì±„ë¬´ ë¶ˆì´í–‰ ì—¬ë¶€'ë¥¼ ëª©í‘œ ë³€ìˆ˜ë¡œ ì„¤ì •

    # ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
    for col in X.select_dtypes(include='object').columns:
        X[col] = X[col].astype('category').cat.codes  # ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ì½”ë“œë¡œ ë³€í™˜

    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ ì¶”ê°€
    scaler = StandardScaler()
    numeric_columns = X.select_dtypes(include=['float64', 'int64']).columns
    X[numeric_columns] = scaler.fit_transform(X[numeric_columns])

    # í•™ìŠµ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°ë¡œ ë‚˜ëˆ„ê¸°
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

    # ê°œë³„ ëª¨ë¸ ì •ì˜ (ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •)
    rf_model = RandomForestClassifier(
        n_estimators=100,    # íŠ¸ë¦¬ ìˆ˜ ì¦ê°€
        max_depth=15,        # íŠ¸ë¦¬ ê¹Šì´ ì¦ê°€
        min_samples_split=5, # ë¶„í• ì„ ìœ„í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
        min_samples_leaf=2,  # ë¦¬í”„ ë…¸ë“œì˜ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
        n_jobs=-1,          # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©
        random_state=42
    )
    
    lr_model = LogisticRegression(
        C=0.1,              # ê·œì œ ê°•ë„ ì¡°ì •
        max_iter=1000,      # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
        class_weight='balanced', # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
        n_jobs=-1,          # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©
        random_state=42
    )

    # ì•™ìƒë¸” ëª¨ë¸ (VotingClassifier)
    ensemble_model = VotingClassifier(
        estimators=[('rf', rf_model), ('lr', lr_model)],
        voting='soft',  # í™•ë¥  ê¸°ë°˜ íˆ¬í‘œ ë°©ì‹ ì‚¬ìš©
        n_jobs=-1      # ë³‘ë ¬ ì²˜ë¦¬ í™œì„±í™”
    )

    # ëª¨ë¸ í•™ìŠµ
    print("\nğŸ”„ ëª¨ë¸ í•™ìŠµ ì¤‘...")
    ensemble_model.fit(X_train, y_train)

    # ê²€ì¦ ì •í™•ë„ ì¶œë ¥
    y_pred = ensemble_model.predict(X_val)
    acc = accuracy_score(y_val, y_pred)
    print(f"\nâœ… ê²€ì¦ ì •í™•ë„ (ì•™ìƒë¸” ëª¨ë¸): {acc:.4f}")
    print("\nğŸ“‹ ë¶„ë¥˜ ë¦¬í¬íŠ¸:\n", classification_report(y_val, y_pred))
    
    return ensemble_model

def predict_and_save(model, test_df, submission_path):
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ 'UID' ì—´ ì œì™¸í•˜ê³  ì˜ˆì¸¡
    X_test = test_df.drop(columns=['UID'])
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
    for col in X_test.select_dtypes(include='object').columns:
        X_test[col] = X_test[col].astype('category').cat.codes  # ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ì½”ë“œë¡œ ë³€í™˜

    # ì˜ˆì¸¡ í™•ë¥  (ì±„ë¬´ ë¶ˆì´í–‰ í™•ë¥ )
    print("\nğŸ”„ ì˜ˆì¸¡ ì¤‘...")
    preds = model.predict_proba(X_test)[:, 1]  # ì–‘ì„± í´ë˜ìŠ¤(ì±„ë¬´ ë¶ˆì´í–‰ í™•ë¥ ) ì˜ˆì¸¡

    # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ submission íŒŒì¼ë¡œ ì €ì¥
    submission = pd.DataFrame({
        'UID': test_df['UID'],
        'ì±„ë¬´ ë¶ˆì´í–‰ í™•ë¥ ': preds
    })
    
    # ê²°ê³¼ ì €ì¥
    submission.to_csv(submission_path, index=False)
    print(f"\nâœ… ì˜ˆì¸¡ ê²°ê³¼ê°€ {submission_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
